#!/bin/bash -exu

RUN_DIR=/var/vcap/sys/run/etcd
PIDFILE=${RUN_DIR}/etcd.pid

source /var/vcap/packages/etcd-common/utils.sh

source /var/vcap/jobs/etcd/bin/etcd_bosh_utils.sh

function wait_for_this_node_to_synchronize() {
  for i in $(seq 55); do
    if /var/vcap/packages/etcd/etcdctl ${etcdctl_sec_flags} -C ${advertise_client_url} ls; then
      synced=true
      break
    fi
    sleep 1
  done
}

function handle_orphaned_etcd() {
  echo "killing etcd with pid ${etcd_pid}"
  kill "${etcd_pid}"
}

case $1 in

  start)

    trap handle_orphaned_etcd TERM

    <% if p("etcd.require_ssl") %>
      set +e
      host -t A <%= p("etcd.dns_health_check_host") %>
      if [[ "0" != "$?" ]]; then
        echo "DNS is not up"
        exit 1
      fi
      set -e
    <% end %>

    pid_guard ${PIDFILE} "etcd"

    if ! mountpoint -q ${STORE_DIR}; then
      echo "WARNING: $STORE_DIR is not on a persistent disk as recommended"
    fi

    export GOMAXPROCS=$(nproc)

    mkdir -p ${RUN_DIR}
    mkdir -p ${LOG_DIR}
    mkdir -p ${DATA_DIR}

    chown -R vcap:vcap ${RUN_DIR}
    chown -R vcap:vcap ${LOG_DIR}
    chown -R vcap:vcap ${DATA_DIR}

    create_cert_files

    # Allowed number of open file descriptors
    ulimit -n 100000

    prior_member_list=$(member_list)

    if [ -z "${prior_member_list}" ]; then
      cluster_state=new
      cluster="${this_node}"
    else
      cluster_state=existing
      cluster=$(extract_cluster_from_member_list "${prior_member_list}")

      # If this node is not in the existing cluster, add it. It generally should
      # not be in the cluster, but if a prior shutdown failed to remove it, we
      # don't want to have it duplicated in the list (etcd server will fail to
      # start). Note extract_my_id determines membership solely based on IP, so
      # this logic is not future-proof against changing node names or ports.
      my_id=$(extract_my_id "${prior_member_list}")
      if [ -z "${my_id}" ]; then
        member_add
        cluster="${cluster},${this_node}"
      fi
    fi

    # Sleep to allow member_add to propagate to entire cluster because starting
    # the server subsequently expects all peers to agree on the cluster members
    sleep 2

    chpst -u vcap:vcap /var/vcap/packages/etcd/etcd ${etcd_sec_flags}                           \
        --name                        ${node_name}                                              \
        --data-dir                    ${DATA_DIR}                                               \
        --heartbeat-interval          <%= p("etcd.heartbeat_interval_in_milliseconds") %> \
        --election-timeout            <%= p("etcd.election_timeout_in_milliseconds") %>   \
        --listen-peer-urls            ${listen_peer_url}                                        \
        --listen-client-urls          ${listen_client_url}                                      \
        --initial-advertise-peer-urls ${advertise_peer_url}                                     \
        --advertise-client-urls       ${advertise_client_url}                                   \
        --initial-cluster             ${cluster}                                                \
        --initial-cluster-state       ${cluster_state}                                          \
        2> >(tee -a ${LOG_DIR}/etcd.stderr.log | logger -p user.error -t vcap.etcd)             \
        1> >(tee -a ${LOG_DIR}/etcd.stdout.log | logger -p user.info  -t vcap.etcd) &

    etcd_pid=$!

    synced=false
    wait_for_this_node_to_synchronize # mutates $synced

    if ${synced}; then
      echo ${etcd_pid} > ${PIDFILE}
    else
      safe_teardown "${prior_member_list}"
      kill -9 ${etcd_pid}
      exit 1
    fi

    ;;

  stop)

    kill_and_wait ${PIDFILE}

    ;;

  *)

    echo "Usage: etcd_ctl {start|stop}"

    ;;

esac
